\documentclass[a4paper]{article}
%\documentclass[a4paper,10pt]{article}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={210mm,297mm},
 left=20mm,
 right=20mm,
 top=20mm,
 bottom=20mm,
 }
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{makeidx}
\usepackage{url}
\usepackage{tikz}
\usepackage{float}
\usepackage{pdfpages}
\usepackage{amsfonts}
\usepackage{mdwlist}
\usepackage{xcolor}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listingsutf8}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{mdframed}
\usepackage[affil-it]{authblk}

\begin{document}
\title{Basic Pollard Rho Algorithm Implementation On \texttt{CUDA} Device}
\author{Martin BerÃ¡nek}
\date{\today}
\affil{Faculty of Information Technology -- Czech Technical University in Prague}
\maketitle

%\tableofcontents
%\listoffigures
%\listoftables

\section{Introduction}

Factorisation problem of a huge number resolved into massive parallel solutions. Large number of algorithms are currently state-of-art and are continuously developed into better forms. This short article is focused on implementation of Pollard-Rho algorithm on \texttt{CUDA} device. In first part there is a definition of algorithm. Next the article focuses on options of parallelism on CUDA device. Results are measured in multiple instances and compared in graphs. 

\section{Definition of the algorithm}

The $\rho$ algorithm (named after the shape of curves symbolising two functions trying to reach themselves in projective space) is based on finding cycle. In $t$ random numbers of $x_1, x_2, \dots, x_t$ in range $[1, n]$ will contain repetition with probability of $P > 0.5$ if $t > 1.777n^{\frac{1}{2}}$

The $\rho$ algorithm uses $g(x)$ for modulo $n$ as a generator for pseudo-random sequence. In this article function $x^2 + k;\, k \in \mathbb{N}$. We are assuming that $n = p \cdot q$ that also mean $p < \sqrt{n}$ and $q < \sqrt{n}$. Algorithm actually generates sequence of $x_1 = g(2),\,x_2 = g(g(2)),\,\dots$ in two separated sequences running in same time. One sequence is generated as $x_1=g(x_0) \mod n$ and second as $x_1=g(g(x_0)) \mod n$. Since we know that $p < \sqrt{n}$ the faster sequence is likely to cycle faster then the sequence generated just in in application of a $g$ function. The repetition of the $\mod p$ will be detected with $| x_k - x_m |$ which will divide $p$ without residue \cite{wiki}.

\begin{figure}[H]
	\centering
	\begin{lstlisting}
    x=2; y=2; d=1
    while d is 1:
        x = g(x)
        y = g(g(y))
        d = gcd(|x - y|, n)
        if d = n: 
            return failure
        else:
            return d
	\end{lstlisting}
	\caption{Sequential pseudo-code of algorithm}
	\label{singl_alg}
\end{figure}

While implementation in \texttt{Python} is basically just a copy of pseudo-code, in \texttt{C} there is plenty struggle with fix size integer size. Another problem will be with transformation of libraries like \texttt{GNU MP}, that's why the basic focus on sequential solution was on basic mathematical operation. For the basic adding and subtracting there was no bigger effort than just creating basic implementation with carry bits. Much more time was spent on operation like division and modulo.

\subsection{Division}

First idea on how to divide numbers was to use school \emph{Long division} algorithm which proved to be little bit expensive but was behaving in the same manners for every input numbers.

\begin{figure}[H]
	\centering
	\begin{lstlisting}
Q = 0
R = 0                     
for i = n - 1 .. 0 do
    R = R << 1
    R(0) = N(i)
    if R >= D then
        R = R - D
        Q(i) = 1
	\end{lstlisting}
	\caption{Long division \cite{long_div}}
	\label{long_div}
\end{figure}

Another much faster division was to use \emph{Knuth's division} \cite{knuth} which took considerably shorter time to compute. Yet there was no luck in implementation. Current version which was considered is from \texttt{llvm} \cite{llvm}. But it failed with some badly shifted bits in residuum hence was not used.

\subsection{\texttt{GCD}}

Since division wasn't fast enough, at least \texttt{GCD} was implemented with shifts and small bit checks. This maybe led to more divergent behaviour in \texttt{CUDA} implementation.

\begin{figure}[H]
	\centering
	\begin{lstlisting}
__device__  inline void gcd(unsigned int * A, unsigned int * B){
    unsigned int t [SIZE];
    unsigned int shift;

    if(zeroNum(B)){
        return;
    }
    if(zeroNum(A)){
        copyNum(A, B);
        return;
    }
    for(shift = 0; ((A[0] | B[0]) & 1) == 0; ++ shift){
        shiftRightNum(A);
        shiftRightNum(B);
    }
    while((A[0] & 1) == 0){
        shiftRightNum(A);
    }
    do{
        while((B[0] & 1) == 0){
            shiftRightNum(B);
        }
        if(bigger(A, B) == 1){
            copyNum(t, B);
            copyNum(B, A);
            copyNum(A, t);
        }
        subNum(B, A);
    } while (! zeroNum(B));
    shiftLeftNumBy(A, shift);
}
	\end{lstlisting}
	\caption{\texttt{GCD} algorithm}
	\label{gcd}
\end{figure}

\section{\texttt{CUDA} Solution}


\subsection{First solution with explicit barrier}

First idea which was found at \url{https://github.com/dghost/factor-cuda}. Implementation prepared at host memory $X, Y, C$ for algorithm which was later on run with multiple kernels and .

\subsection{Second solution with independent runners}


\section{Conclusion}

\bibliographystyle{iso690}
\bibliography{mybibliographyfile}


\appendix

\end{document}
